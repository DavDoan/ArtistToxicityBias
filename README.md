# ArtistToxicityDetection

Dependencies: Libraries utilized are mentioned at the beginning of the ArtistToxicityBias.ipynb file. A Google Perspective API key is also required to run the ipynb file provided.

This is a short project that leverages Google's Perspective API to detect the toxicity of social media comments left underneath art posts. I'm then assessing whether Google's Perspective API is biased against comments left under artist accounts with a large following (over 5000 followers) or accounts with a smaller following (under 5000 followers). 

Hypothesis: I hypothesize the Perspective API will misclassify toxic comments in art accounts with a larger following compared to smaller accounts. I believe this because I expect comments in larger accounts will be primarily non-toxic as many individuals already support the art creator.

Method: I created two dataframes based on how many followers the artist account has. Then, I fed the Google Perspective API both comment lists, compiling the returned output into two separate lists based on following size. With a TOXICITY score of 0.5 being our threshhold value, I then created a list of binary values that represented the API's toxicity predictions. Afterwards, I used gauged the accuracy, precision, recall, and f1-score of the API's predictions to the actual score.

Drawback: There is no established dataset that includes the comment attributes I desire, so I created a small dataset used specifically for this project. The comments are gathered from several social media platforms and from several social media accounts, so the strength of the analyzed data is to be questioned. 

Results: Google's Perspective API was more accurate at identifying toxic comments in social media posts made by art creators with a smaller following. This can stem from a number of reasons, but a large reason for the decreased accuracy in larger accounts is the f1-score in identifying toxic comments. The API misidentified all the toxic comments for larger creators; on the other hand, the API misidentified half of the toxic comments for smaller creators. The large disparity of f1-scores between large and small social media accounts, especialy when correctly identifying toxic comments, suggests there is bias. Since the precision, recall, and f1-scores are notably lower in identifying toxic comments for larger art accounts compared to smaller accounts, suggesting there is a bias that causes decreased accuracy when identifying toxic comments in larger accounts. This demonstrates the API's tendency to identify comments made under art accounts with a larger following as non-toxic, suggesting the API is biased against smaller art accounts.

Post-Analysis: I believe Google's Perspective API underperformed when identifying toxicity in artist social media comments because comments found under creative and artistic posts are normally positive and filled with constructive criticism. Any comments that can be considered 'toxic' are usually snide and discredit the art creator, and because they aren't usually filled with obscenities, the Perspective API would have a more difficult time identifying toxic posts with sarcasm that attack the art creator.
